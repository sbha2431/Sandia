We begin by defining a formal model for describing multi-agent surveillance strategy synthesis problems, in the form of a two-player game between the mobile sensors and a target, in which the sensors have only partial information about the target's location. For ease of notation the definitions are provided for the case of a single target. \Rayna{I think we should remove the last sentence, since we are not looking at multiple targets yet, and it is not just a simple extension of notation.}

\subsection{Surveillance Game Structures}\label{sec:surveillance-games}
We define a \emph{multi-agent surveillance game structure} to be  a tuple $G  = (\states,s^\init,\trans,\vis_1,\dots,\vis_n,\Vis)$, with the following components:
\begin{itemize}
\item $\states = L \times L_t$ is the set of states, where $L = L_{1} \times L_{2} \times\dots \times L_{n}$ is the set of joint locations of the $n$ sensors, $L_i$ is the set of possible locations of sensor $i$,  and $L_t$ is the set of possible locations of the target;
\item $s^\init = (l^{\init}_1,\ldots,l^{\init}_n,l_t^\init)$ is the initial state;
\item $\trans \subseteq \states \times \states$ is the transition relation describing the possible joint moves of the sensors and the target;
\item  $(\vis_1,\dots,\vis_n)$ are the \textit{visibility functions} for the $n$ agents, where $\vis_i: L_{i} \times L_t \to \bools$ maps a state $(l_{i},l_t)$ to $\true$ iff \emph{ position $l_t$ is in the area of sight of $l_i$}; and
\item  $\Vis : \states \to \bools$ is the \emph{joint visibility function} that maps a state $(l,l_t)$ to $\true$ if the set $\mathcal{I} = \{i \mid \vis_i(l_i,l_t) = \true\}$ is non-empty. Informally, $\Vis(l,l_t)$ is $\true$ if the target is in view of \emph{at least one} of the sensors.
\end{itemize}
\Rayna{Since $\Vis$ is determined by $(\vis_1,\dots,\vis_n)$ we can actually define it outside of the definition.}

\Rayna{We should perhaps assume that $L_1 = \ldots = L_n$ for the later partitioning into regions for each sensor.}

\begin{figure}
\subfloat[Surveillance arena \label{simple-grid}]{
%\includegraphics[scale=.33]{figs/7x7_safety.png}
\begin{tikzpicture}[scale=0.8]
\draw[step=0.5cm,color=gray] (-1.5,-1.5) grid (1,1);
\filldraw[fill=blue,draw=black] (+0.75,+0.75) circle (0.2cm);

\filldraw[fill=red,draw=black] (0,0) rectangle (-0.5,-0.5);
\filldraw[fill=red,draw=black] (-0.5,0) rectangle (-1,-0.5);
\filldraw[fill=red,draw=black] (0,0) rectangle (0.5,-0.5);
\filldraw[fill=blue!40!white,draw=black] (+0.75,+0.75) circle (0.2cm);
\filldraw[fill=orange!40!white,draw=black] (0.25,-0.75) circle (0.2cm);
\filldraw[fill=green!40!white,draw=black]  (-1.25,+0.75) circle (0.2cm);
\node at (-1.25,+0.75) {\tiny{0}};
\node at (-0.80,+0.75) {\tiny{1}};
\node at (-0.30,+0.75) {\tiny{2}};
\node at (0.20,+0.75) {\tiny{3}};
\node at (0.73,+0.75) {\tiny{4}};
\node at (-1.33,+0.25) {\tiny{5}};
\node at (-0.85,+0.25) {\tiny{6}};
\node at (-0.35,+0.25) {\tiny{7}};
\node at (0.25,+0.25) {\tiny{8}};
\node at (0.75,+0.25) {\tiny{9}};
\node at (-1.28,-0.27) {\tiny{10}};
\node at (-0.78,-0.27) {\tiny{11}};
\node at (-0.28,-0.27) {\tiny{12}};
\node at (0.28,-0.27) {\tiny{13}};
\node at (0.75,-0.25) {\tiny{14}};
\node at (-1.3,-0.75) {\tiny{15}};
\node at (-0.8,-0.75) {\tiny{16}};
\node at (-0.3,-0.75) {\tiny{17}};
\node at (0.25,-0.75) {\tiny{18}};
\node at (0.75,-0.75) {\tiny{19}};
\node at (-1.35,-1.25) {\tiny{20}};
\node at (-0.85,-1.25) {\tiny{21}};
\node at (-0.35,-1.25) {\tiny{22}};
\node at (0.25,-1.25) {\tiny{23}};
\node at (0.75,-1.25) {\tiny{24}};
\end{tikzpicture}
\hspace{.3cm}}
%\hfill
\subfloat[Transitions from the initial state\label{fig:simple-transitions}]{
\input{figs/simple-transitions.tex}
}
\vspace{-0.1cm}
\caption{A simple surveillance game on a grid arena. Obstacles are shown in red. There are two sensors (at locations 0 and 4) coloured in blue and green respectively and the target (at location 18) is orange.\todo{\textbf{modify for 2 sensor example}}}
\label{fig:simple-surveillance-game}
\vspace{-.7cm}
\end{figure}


The transition relation $T$ encodes the one-step move of the target and the $n$ sensors: First, the target makes a move, after that, the sensors move jointly in a synchronized manner. 

For a state $(l,l_t)$ we denote $\succs_t(l,l_t)$ as the set of successor locations of the target:

$\succs_t(l,l_{t}) = \{l_{t}' \in L_t \mid \exists l'.\ ((l,l_t),(l',l_t')) \in T\}$.

We extend $\succs_t$ to sets of locations of the target by stipulating that the set $\post(l,L)$ consists of all possible successor locations of the target for states in $\{l\} \times L$. Formally, let $\post(l, L) = \bigcup_{l_t \in L_t}\succs_t(l,l_t)$.

For a state $(l,l_t)$ and a successor location of the target $l_t'$, we denote with $\succs(l,l_t,l_t')$ the set of successor locations of the sensors, given that the target moves to $l_t'$: 

$\succs(l,l_t,l_t') = \{l' \in L \mid  ((l,l_t),(l',l_t')) \in T\}$.

We assume that, for every state $s\in \states$, there exists a state $s' \in \states$ such that $(s,s') \in T$, that is, from every state there is at least one move possible (this might be staying in the same state). We also assume that when the target moves to an invisible location, its position does not influence the possible one-step moves of the sensors. Formally, we require that if $\Vis(l,l_t''') = \Vis(l,l_t'''')=\false$, then $\succs(l,l_t',l_t''') = \succs(l,l_t'',l_t'''')$ for all $l_t',l_t'',l_t''',l_t'''' \in L_t$. This assumption is natural in the setting where each of the  sensors can move in one step only to locations that are in its sight.

\begin{example}\label{ex:simple-surveillance-game}\todo{make this for multiple sensors}
Figure~\ref{fig:simple-surveillance-game} shows an example of a surveillance game on a grid.  The sets of possible locations $L$ and $L_t$ for the sensors and the target consist of the squares of the  grid. The transition relation $T$ encodes the possible one-step moves of all the sensors and the target on the grid, and incorporates all desired constraints. For example, moving to an occupied location, or an obstacle, is not allowed. Figure~\ref{fig:simple-transitions} shows the possible transitions from the initial state $(4,18)$.

In this example, the function $\vis_i$ encodes straight-line visibility: a location $l_t$ is visible to sensor $i$ from location $l_i$ if there is no obstacle on the straight line between them. Initially the target is not in the area of sight of the sensors, but the initial position of the target is known. However, once the target moves to one of the locations reachable in one step, in this case, locations $\{17,19,23\}$, this might no longer be the case. More precisely, if the target moves to location $19$, then the blue sensor observes its location, but if it moves to one of the others, then neither sensor can observe it and its exact location will not be known. \qed
\end{example}




\subsection{Belief-Set Game Structures}

In surveillance strategy synthesis we need to state properties of, and reason about, the information which the sensors have, i.e. the \emph{belief} about the location of the target. To this end, we can employ a powerset construction which is commonly used to transform a partial-information game into a perfect-information one, by explicitly tracking the joint knowledge of the sensors as a set of possible states of the target. In that way we define a two-player game in which one player represents the whole sensor network, and the other player represents the target.

Given a set $B$, we denote with $\mathcal{P}(B) = \{B' \mid B'\subseteq B\}$ the powerset (set of all subsets) of $B$.

For a surveillance game structure $G  = (\states,s^\init,\trans,\vis_1,\ldots,\vis_n,\Vis)$ we define the corresponding \emph{belief-set game structure} $G_\belief  = (\states_\belief,s^\init_\belief,\trans_\belief)$ with the following components:
\begin{itemize}
\item $\states_\belief = L \times \beliefs$ is the set of states, with $L$ the set of locations of the sensors, and $\beliefs$ the set of \emph{belief sets} describing information about the location of the target;
\item $s^\init_\belief = (l^\init_1,\ldots,l^\init_n,\{l_t^\init\})$ is the initial state;
\item $\trans_\belief \subseteq \states_\belief \times \states_\belief$ is the transition relation where $((l, B_t),(l', B_t')) \in \trans_\belief$ iff $l' \in  \succs(l,l_t,l_t')$ for some $l_t \in B_t$ and $l_t' \in B_t'$ and one of these holds:
\begin{itemize}
\item[(1)] $B_t' = \{l_t'\}$, $l_t' \in \post(l,B_t)$, $\Vis(l,l_t') = \true$;
\item[(2)] $B_t' = \{l_t' \in \post(l,B_t)  \mid  \Vis(l,l_t') = \false \}$.
%\item[(1)] $B_t' = \{l_t'\}$ for some $l_t'$ such that $\vis(l_a,l_t') = \true$ and
%there exists $l_t \in B_t$ with $((l_a,l_t),(l_a',l_t')) \in \trans$;
%\item[(2)] $\begin{array}{lll}
%B_t' = \{l_t' & \mid & \vis(l_a,l_t') = \false \text{ and } \\
%&& \exists l_t \in B_t.\ ((l_a,l_t),(l_a',l_t')) \in \trans\}. 
%\end{array}
%$
\end{itemize}
\end{itemize}
Condition (1) captures the successor locations of the target that can be observed from one of the sensors' current location. Condition (2) corresponds to the belief set consisting of \emph{all possible successor locations of the target not visible from the current location of any of the sensors}. 
%\begin{itemize}
%\item[(1)] $B_t' = \{l_t'\}$ for some $l_t'$ such that $\vis(l_a,l_t') = \true$ and
%there exists $l_t \in B_t$ with $((l_a,l_t),(l_a',l_t')) \in \trans$;
%\item[(2)] there exists $l_t \in B_t$ such that $\vis(l_a,l_t) = \true$ and 
%$\begin{array}{lll}
%B_t' = \{l_t' & \mid & \vis(l_a,l_t') = \false \text{ and } \\
%&& ((l_a,l_t),(l_a',l_t')) \in \trans\};
%\end{array}
%$
%\item[(3)] $\begin{array}{lll}
%B_t' = \{l_t' & \mid & \vis(l_a,l_t') = \false \text{ and } \\
%&& \exists l_t \in B_t: \vis(l_a,l_t') = \false \\
%&& \text{and }  ((l_a,l_t),(l_a',l_t')) \in \trans\}.
%\end{array}
%$
%\end{itemize}
%The first condition captures the successor locations of the target that can be observed from the agent's current location $l_a$. Conditions (2) and (3) correspond to belief sets consisting of all possible successor locations of the target not visible from $l_a$. In (2) those are successors of a single possible current position $l_t$ of the target that is visible from $l_a$, while in (3) the belief consist of  successors of all positions in $B_t$ not visible from $l_a$.

%\noindent{\textit{Remark}} In our model, before making a move, the agent updates its belief about the target. Thus, the belief set at each step consists of the locations the target can be in, after it moves (since it moves first). Since the target moves again immediately after the agent moves, the agent does not update its belief after it completes its own move. We note that the results in this paper can be easily extended to the case when the belief is updated after each player's move by explicitly incorporating turn-switching in the model. We choose not do so, for the sake of keeping the presentation simple.

\begin{figure}
\input{figs/simple-belief-transitions.tex}

\vspace{-.3cm}
\caption{Transitions from the initial state in the belief-set game from Example~\ref{ex:simple-belief-game} where $\vis(4,17) = \vis(4,23) = \false$. \todo{\textbf{Modify for 2 sensor example}}}
\label{fig:simple-belief-game}
\vspace{-.5cm}
\end{figure}

\begin{example}\label{ex:simple-belief-game}
Consider the surveillance game structure from Example~\ref{ex:simple-surveillance-game}. The initial belief set is $\{18\}$, as the target's initial position is known. After the first move of the target, there are two possible belief sets: the set $\{19\}$ resulting from the move to a location in the area of sight of the blue sensor, and $\{17,23\}$ consisting of the two locations invisible to both sensors reachable in one step from location $18$.
Figure~\ref{fig:simple-belief-game} shows the successor states of the initial state $((0,4),\{18\})$ in $G_\belief$. \qed
\end{example}

Based on  $T_\belief$, we can define the functions $\succs_t : \states_\belief \to \mathcal{P}(\beliefs)$ and  $\succs : \states_\belief \times \beliefs \to \mathcal{P}(L)$ similarly to the corresponding functions defined for $G$. 

A \emph{run} in $G_\belief$ is an infinite sequence $s_0,s_1,\ldots$ of states in $\states_\belief$, where $s_0 = s_\belief^\init$,  $(s_i,s_{i+1}) \in T_\belief$ for all $i$. 

A \emph{strategy for the target in $G_\belief$} is a function $f_t: \states_\belief^+ \to \beliefs$ such that $f_t(\pi\cdot s) = B_t$ implies $B_t \in \succs_t(s)$ for every $\pi \in \states_\belief^*$ and $s \in \states_\belief$. That is, a strategy for the target suggests a move resulting in some belief set reachable from some location in the current belief.

A \emph{joint strategy for the sensors in $G_\belief$} is a function $f_s : S^+ \times \beliefs \to S$ such that $f_s(\pi\cdot s,B_t) = (l_a',B_t')$ implies $B_t' = B_t$ and $l_a' \in \succs_a(s,B_t)$ for every $\pi \in \states_\belief^*$, $s \in \states_\belief$ and $B_t \in \beliefs$. Intuitively, a strategy for the sensors suggests a joint move based on the observed history of the play and the current belief about the target's position.

The outcome of given strategies $f_s$ and $f_t$ for the sensors and the target in $G_\belief$, denoted $\outcome(G_\belief,f_s,f_t)$, is a run $s_0,s_1,\ldots$ of $G_\belief$ such that for every $i \geq 0$, we have $s_{i+1} = f_s(s_0,\ldots,s_i,B_t^i)$, where $B_t^i = f_t(s_0,\ldots,s_i)$.

\subsection{Temporal Surveillance Objectives}
Since the states of a belief-set game structure track the information that the sensors have, we can state and interpret surveillance objectives over its runs. We now formally define the surveillance properties in which we are interested. 

We consider a set of \emph{surveillance predicates} $\SP = \{p_k \mid k \in \nats_{>0}\}$, where for $k \in \nats_{>0}$ we say that a state $(l,B_t)$ in the belief game structure satisfies $p_k$ (denoted $(l,B_t) \models p_k$) iff 
$|\{l_t \in B_t \mid \Vis(l,l_t)  = \false \}| \leq k$. Intuitively, $p_k$ is satisfied by the states in the belief game structure where the size of the belief set does not exceed the threshold $k \in \nats_{>0}$.

We study surveillance objectives expressed by formulas of linear temporal logic (LTL) over surveillance predicates.
% Since we are only interested in surveillance predicates that upper-bound the size of belief sets, we consider LTL formulas in negation normal form, in which we disallow the occurrence of negation in front of surveillance predicates.
 The LTL surveillance formulas  are generated by the grammar\\
$\varphi := p \mid \true \mid \false \mid \varphi \wedge \varphi \mid \varphi \vee \varphi \mid \LTLnext  \varphi  \mid \varphi \LTLuntil \varphi \mid \varphi \LTLrelease \varphi,$\\
where $p \in \SP$ is a surveillance predicate, $\LTLnext$ is the \emph{next} operator, $\LTLuntil$ is the \emph{until} operator, and $\LTLrelease$ is the \emph{release} operator. We also define the derived operators 
\emph{finally}: $\LTLfinally \varphi = \true \LTLuntil \varphi$ and 
\emph{globally}: $\LTLglobally \varphi = \false \LTLrelease \varphi$.

LTL formulas are interpreted over (infinite) runs. If a run $\rho$ satisfies an LTL formula $\varphi$, we write $\rho \models \varphi$. The formal definition of LTL semantics can be found in~\cite{BaierKatoen08}. Here we informally explain the meaning of the formulas we use.

Of special interest will be surveillance formulas of the form $\LTLglobally p_k$, termed \emph{safety surveillance objective}, and $\LTLglobally\LTLfinally p_k$, called \emph{liveness surveillance objective}.
Intuitively, the safety surveillance formula $\LTLglobally p_k$ is satisfied if at each point in time the size of the belief set does not exceed $k$. The liveness surveillance objective $\LTLglobally\LTLfinally p_k$, on the other hand, requires that infinitely often this size is below or equal to $k$.

\begin{example}
We can specify that the sensors are required to always know with certainty the location of the target as
$\LTLglobally p_1$.
A more relaxed requirement is that the sensors' uncertainty never grows above $5$ locations, and it infinitely often reduces this uncertainty to at most $2$ locations: $\LTLglobally p_5 \wedge \LTLglobally\LTLfinally p_2$.
\qed
\end{example}


%\subsection{Incorporating Task Specifications}
%We can integrate LTL objectives not related to surveillance, i.e., \emph{task specifications}, by considering, in addition to $\SP$, a set $\AP$ of atomic predicates interpreted over states of $G$. In order to define the semantics of $p \in \AP$ over states of $G_\belief$, we restrict ourselves to predicates observable by the agent. 
%Formally, we require that for $p \in \AP$, and states $(l_a,l_t')$ and $(l_a,l_t'')$ with $\vis(l_a,l_t')=\vis(l_a,l_t'')=\false$ it holds that $(l_a,l_t') \models p$ iff $(l_a,l_t'') \models p$. One class of such predicates are those that depend only on the agent's position.

%\begin{example}
%Suppose that $\mathit{at\_goal}$ is a predicate true exactly when the agent is at some designated goal location. We can then state that the agent visits the goal infinitely often while always maintaining belief uncertainty of at most $10$ locations using the LTL formula $\LTLglobally\LTLfinally \mathit{at\_goal} \wedge \LTLglobally p_{10}$.
%\qed
%\end{example}

\subsection{Multi-agent Surveillance Synthesis Problem}
A \emph{multi-agent surveillance game} is a pair $(G,\varphi)$, where $G$ is a surveillance game structure and $\varphi$ is a surveillance objective. A \emph{winning strategy for the sensors for $(G,\varphi)$} is a joint strategy $f_s$ for the sensors in the corresponding belief-set game structure $G_\belief$ such that for every strategy $f_t$ for the target in $G_\belief$ it holds that $\outcome(G_\belief,f,f_t) \models \varphi$. Analogously, a \emph{winning strategy for the target for $(G,\varphi)$} is a strategy $f_t$ such that, for every strategy $f_s$ for the sensors in $G_\belief$, it holds that $\outcome(G_\belief,f_s,f_t) \not\models \varphi$.

{\bf Multi-agent surveillance synthesis problem:} Given a multi-agent surveillance game $(G,\varphi)$, compute a joint winning strategy for the sensors for the game $(G,\varphi)$, or determine that such a strategy does not exist.

There are two sources of computational complexity in the multi-agent surveillance synthesis problem. Firstly, reasoning about belief sets leads to an exponential increase in the state space of the game. Methods such as constructing an \emph{abstract belief game} to mitigate the state space explosion have been proposed \cite{}. However, in the worst case that method can still result in the full exponentially-large state space. The second source of complexity are the multiple sensors. While adding more mobile sensors can help enforce stronger surveillance objectives, the size of the state space is exponential in the number of sensors (assuming all sensors have the same set of possible locations). In the next section we propose a method that aims to overcome this second source of complexity. The key idea is to decompose the multi-agent surveillance synthesis problem into a set of single-sensor surveillance games over smaller sets of locations. To achieve this, we make use of a compositionality property of surveillance games. Intuitively, by partitioning the set of locations into $n$ regions and allocating one mobile sensor per region we can, under certain conditions, solve the global surveillance game by solving $n$ smaller \emph{surveillance subgames}. 